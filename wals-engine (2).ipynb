{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that tensorflow.contrib is only supported by 1.x version of tensorflow. \n",
    "To avoid import error install lower version of the libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15 in /opt/conda/lib/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.19.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.31.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.35.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (3.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.15) (49.6.0.post20200814)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorlow version: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.factorization.python.ops import factorization_ops\n",
    "print('Tensorlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the 100k movielens data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file\n",
    "!unzip ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory \"data\" and copy the user rating data \"u.data\" into it\n",
    "\n",
    "!mkdir -p data\n",
    "!cp ml-100k/u.data data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  ml-100k  ml-100k.zip  readme.md  wals-engine.ipynb  wals.ipynb\n",
      ">>u.data\n",
      "196\t242\t3\t881250949\n",
      "186\t302\t3\t891717742\n",
      "22\t377\t1\t878887116\n",
      "244\t51\t2\t880606923\n",
      "166\t346\t1\t886397596\n",
      "298\t474\t4\t884182806\n",
      "115\t265\t2\t881171488\n",
      "253\t465\t5\t891628467\n",
      "305\t451\t3\t886324817\n",
      "6\t86\t3\t883603013\n"
     ]
    }
   ],
   "source": [
    "# get the list of files in the working directory and take a look at the user rating dataset\n",
    "\n",
    "!ls\n",
    "!echo \">>u.data\"\n",
    "!head data/u.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/u.data'\n",
    "headers = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "header_row = None\n",
    "ratings_df = pd.read_csv(input_file,\n",
    "                         sep='\\t',\n",
    "                         names=headers,\n",
    "                         header=header_row,\n",
    "                         dtype={\n",
    "                           'user_id': np.int32,\n",
    "                           'item_id': np.int32,\n",
    "                           'rating': np.float32,\n",
    "                           'timestamp': np.int32,\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users: 943\n",
      "Total number of items: 1682\n",
      "ratings_df.shape = (100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242     3.0  881250949\n",
       "1      186      302     3.0  891717742\n",
       "2       22      377     1.0  878887116\n",
       "3      244       51     2.0  880606923\n",
       "4      166      346     1.0  886397596"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_unique(colnm):\n",
    "    \"\"\"returns the number of unique values in a given column\"\"\"\n",
    "    \n",
    "    n = len(np.unique(ratings_df[colnm]))\n",
    "    return(n)\n",
    "\n",
    "n_users = n_unique(\"user_id\")    \n",
    "n_items = n_unique(\"item_id\") \n",
    "\n",
    "print(\"Total number of users:\",n_users)\n",
    "print(\"Total number of items:\",n_items)\n",
    "\n",
    "print(\"ratings_df.shape =\",ratings_df.shape)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>462.48475</td>\n",
       "      <td>425.530130</td>\n",
       "      <td>3.529860</td>\n",
       "      <td>8.835289e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>266.61442</td>\n",
       "      <td>330.798356</td>\n",
       "      <td>1.125754</td>\n",
       "      <td>5.343856e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.747247e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>254.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.794487e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.00000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.828269e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>682.00000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.882600e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.00000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.932866e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id        item_id         rating     timestamp\n",
       "count  100000.00000  100000.000000  100000.000000  1.000000e+05\n",
       "mean      462.48475     425.530130       3.529860  8.835289e+08\n",
       "std       266.61442     330.798356       1.125754  5.343856e+06\n",
       "min         1.00000       1.000000       1.000000  8.747247e+08\n",
       "25%       254.00000     175.000000       3.000000  8.794487e+08\n",
       "50%       447.00000     322.000000       4.000000  8.828269e+08\n",
       "75%       682.00000     631.000000       4.000000  8.882600e+08\n",
       "max       943.00000    1682.000000       5.000000  8.932866e+08"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    100000 non-null  int32  \n",
      " 1   item_id    100000 non-null  int32  \n",
      " 2   rating     100000 non-null  float32\n",
      " 3   timestamp  100000 non-null  int32  \n",
      "dtypes: float32(1), int32(3)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3) float64\n",
      "start indexing at: 0.0 end indexint at: 942.0\n",
      "start indexing at: 0.0 end indexint at: 1681.0\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings_df[['user_id', 'item_id', 'rating']].values\n",
    "ratings[:,0] -= 1\n",
    "ratings[:,1] -= 1\n",
    "\n",
    "print(ratings.shape,ratings.dtype)\n",
    "for i in [0,1]:\n",
    "    print(\"start indexing at:\",np.min(ratings[:,i]),\"end indexint at:\",np.max(ratings[:,i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sparse train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_sparse_train_and_test(ratings, n_users, n_items):\n",
    "    \n",
    "    \"\"\"Given ratings, create sparse matrices for train and test sets.\n",
    "    Args:\n",
    "      ratings:  list of ratings tuples  (u, i, r)\n",
    "      n_users:  number of users\n",
    "      n_items:  number of items\n",
    "      \n",
    "    Returns:\n",
    "       train, test sparse matrices in scipy coo_matrix format.\n",
    "       \n",
    "    \"\"\"\n",
    "    print(\"Ratings shape: {}, minimum rating: {}, number of users: {}, number of items: {}\".\n",
    "          format(ratings.shape,ratings.min(),n_users,n_items))\n",
    "\n",
    "    # pick a test size\n",
    "    test_set_size = int(len(ratings) * TEST_SET_RATIO)\n",
    "    print('Test set size:{}'.format(test_set_size))\n",
    "    \n",
    "    # select indexes randomly for the test set\n",
    "    np.random.seed(1)\n",
    "    test_set_idx = np.random.choice(range(len(ratings)),\n",
    "                                    size=test_set_size, replace=False)\n",
    "    test_set_idx = sorted(test_set_idx)\n",
    "\n",
    "    # sift ratings into train and test sets\n",
    "    ts_ratings = ratings[test_set_idx]\n",
    "    tr_ratings = np.delete(ratings, test_set_idx, axis=0)\n",
    "    \n",
    "    # create training and test matrices as coo_matrix's\n",
    "    u_tr, i_tr, r_tr = zip(*tr_ratings)\n",
    "    tr_sparse = coo_matrix((r_tr, (u_tr, i_tr)), shape=(n_users, n_items))\n",
    "\n",
    "    u_ts, i_ts, r_ts = zip(*ts_ratings)\n",
    "    test_sparse = coo_matrix((r_ts, (u_ts, i_ts)), shape=(n_users, n_items))\n",
    "\n",
    "    return tr_sparse, test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape: (100000, 3), minimum rating: 0.0, number of users: 943, number of items: 1682\n",
      "Test set size:10000\n",
      "\n",
      "Train sparse matrix dimension: (943, 1682)\n",
      "Number of train sparse matix rows: (90000,)\n",
      "Number of train sparse matix colunms: (90000,)\n",
      "\n",
      "Test sparse matrix dimension: (943, 1682)\n",
      "Number of test sparse matix rows: (10000,)\n",
      "Number of test sparse matix colunms: (10000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 10% of the data will be test set.\n",
    "TEST_SET_RATIO = 0.1\n",
    "tr_sparse, test_sparse = _create_sparse_train_and_test(ratings, n_users, n_items)\n",
    "\n",
    "print(\"\\nTrain sparse matrix dimension: {}\".format(tr_sparse.shape))\n",
    "print(\"Number of train sparse matix rows: {}\".format(tr_sparse.row.shape))\n",
    "print(\"Number of train sparse matix colunms: {}\\n\".format(tr_sparse.col.shape))\n",
    "\n",
    "print(\"Test sparse matrix dimension: {}\".format(test_sparse.shape))\n",
    "print(\"Number of test sparse matix rows: {}\".format(test_sparse.row.shape))\n",
    "print(\"Number of test sparse matix colunms: {}\\n\".format(test_sparse.col.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make weights function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear and log ratings\n",
    "Notice that both weights are inversely related to the number of users rating the jth item, \n",
    "so that the weights down weights the item that have large number of observed ratings. \n",
    "The following code visualizes these weights for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wts(data, wt_type, obs_wt, feature_wt_exp, axis):\n",
    "    \"\"\"Generate observed item weights.\n",
    "      Args:\n",
    "        data:             coo_matrix of ratings data\n",
    "        wt_type:          weight type, LOG_RATINGS or LINEAR_RATINGS\n",
    "        obs_wt:           linear weight factor\n",
    "        feature_wt_exp:   logarithmic weight factor\n",
    "        axis:             axis to make weights for, 1=rows/users, 0=cols/items\n",
    "      Returns:\n",
    "        vector of weights for cols (items) or rows (users)\n",
    "    \"\"\"\n",
    "    assert wt_type in [\"LOG_RATINGS\",\"LINEAR_RATINGS\"]\n",
    "    # recipricol of sum of number of items across rows (if axis is 0)\n",
    "    frac = np.array(1.0/(data > 0.0).sum(axis))\n",
    "    \n",
    "    # filter any invalid entries i.e unrated movies\n",
    "    frac[np.ma.masked_invalid(frac).mask] = 0.0\n",
    "    \n",
    "    # normalize weights according to assumed distribution of ratings\n",
    "    if wt_type == \"LOG_RATINGS\":\n",
    "        wts = np.array(np.power(frac, feature_wt_exp)).flatten()\n",
    "    elif wt_type == \"LINEAR_RATINGS\":\n",
    "        wts = np.array(obs_wt * frac).flatten()\n",
    "    \n",
    "    # check again for any numerically unstable entries\n",
    "    assert np.isfinite(wts).sum() == wts.shape[0]\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_graph(data,PARAMS):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        \n",
    "\n",
    "        input_tensor = tf.SparseTensor(indices=np.array([data.row, data.col]).T,\n",
    "                                       values=(data.data).astype(np.float32),\n",
    "                                       dense_shape=data.shape)\n",
    "\n",
    "\n",
    "        row_wts = None\n",
    "        col_wts = None\n",
    "        num_rows = data.shape[0]\n",
    "        num_cols = data.shape[1]\n",
    "\n",
    "        # initialize the weights \n",
    "        if PARAMS[\"wt_type\"] in [\"LOG_RATINGS\",\"LINEAR_RATINGS\"]:\n",
    "            row_wts = np.ones(num_rows)\n",
    "            col_wts = make_wts(data, \n",
    "                               PARAMS[\"wt_type\"], \n",
    "                               PARAMS['feature_wt_factor'],\n",
    "                               PARAMS['feature_wt_exp'],axis=0)\n",
    "            \n",
    "            #initalize the WALS model instance\n",
    "\n",
    "        model = factorization_ops.WALSModel(num_rows, num_cols, PARAMS[\"latent_factors\"],\n",
    "                                            unobserved_weight=PARAMS[\"unobs_weight\"],\n",
    "                                            regularization=PARAMS[\"regularization\"],\n",
    "                                            row_weights=row_wts,\n",
    "                                            col_weights=col_wts)\n",
    "\n",
    "        return(graph,model,input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a tensorflow session to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(graph,model,input_tensor,verbose=False):   \n",
    "    sess = tf.Session(graph=graph)\n",
    "    with graph.as_default():\n",
    "        row_update_op = model.update_row_factors(sp_input=input_tensor)[1]\n",
    "        col_update_op = model.update_col_factors(sp_input=input_tensor)[1]\n",
    "\n",
    "        sess.run(model.initialize_op)\n",
    "        sess.run(model.worker_init)\n",
    "        for i in range(num_iterations):\n",
    "            sess.run(model.row_update_prep_gramian_op)\n",
    "            sess.run(model.initialize_row_update_op)\n",
    "            sess.run(row_update_op)\n",
    "            sess.run(model.col_update_prep_gramian_op)\n",
    "            sess.run(model.initialize_col_update_op)\n",
    "            sess.run(col_update_op)\n",
    "            if verbose and i % 1 == 0:\n",
    "                rf = sess.run(row_factor)\n",
    "                print(\"iter\",i,rf.mean(),rf.min(),sess.run(col_factor).mean())\n",
    "    return sess "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to find the Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(output_row, output_col, actual):\n",
    "        \"\"\"Compute rmse between predicted and actual ratings.\n",
    "        Args:\n",
    "          output_row: evaluated numpy array of row_factor\n",
    "          output_col: evaluated numpy array of col_factor\n",
    "          actual: coo_matrix of actual (test) values\n",
    "        Returns:\n",
    "          rmse\n",
    "        \"\"\"\n",
    "        mse = 0\n",
    "        rate_preds = []\n",
    "        for i in range(actual.data.shape[0]):\n",
    "            row_pred = output_row[actual.row[i]]\n",
    "            col_pred = output_col[actual.col[i]]\n",
    "            rate_pred = np.dot(row_pred, col_pred)\n",
    "            rate_preds.append(rate_pred)\n",
    "            err = actual.data[i] - rate_pred\n",
    "            mse += err * err\n",
    "        mse /= actual.data.shape[0]\n",
    "        rmse = math.sqrt(mse)\n",
    "        return rmse,rate_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initalize the hyper parameters needed for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'regularization': 0.01,\n",
    "    'unobs_weight': .001,  \n",
    "    'feature_wt_factor': 189.8,\n",
    "    'feature_wt_exp': 0.08,\n",
    "}\n",
    "latent_factors  = [1,  2,   5, 15]\n",
    "regularizations = [0.001,0.1,  5, 20,100]\n",
    "wt_types = [\"UNIFORM\",\"LINEAR_RATINGS\",\"LOG_RATINGS\"]\n",
    "rmse_best = np.Inf\n",
    "num_iterations = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIFORM\n",
      "           latent factor   1, reg   0.0, rmse (train)  2.87, rmse (test)  2.89\n",
      "           latent factor   1, reg   0.1, rmse (train)  2.87, rmse (test)  2.89\n",
      "           latent factor   1, reg   5.0, rmse (train)  2.87, rmse (test)  2.89\n",
      "           latent factor   1, reg  20.0, rmse (train)  2.87, rmse (test)  2.89\n",
      "           latent factor   1, reg 100.0, rmse (train)  2.87, rmse (test)  2.88\n",
      "           latent factor   2, reg   0.0, rmse (train)  2.75, rmse (test)  2.78\n",
      "           latent factor   2, reg   0.1, rmse (train)  2.75, rmse (test)  2.78\n",
      "           latent factor   2, reg   5.0, rmse (train)  2.75, rmse (test)  2.78\n",
      "           latent factor   2, reg  20.0, rmse (train)  2.75, rmse (test)  2.78\n",
      "           latent factor   2, reg 100.0, rmse (train)  2.75, rmse (test)  2.78\n",
      "           latent factor   5, reg   0.0, rmse (train)  2.56, rmse (test)  2.61\n",
      "           latent factor   5, reg   0.1, rmse (train)  2.57, rmse (test)  2.62\n",
      "           latent factor   5, reg   5.0, rmse (train)  2.57, rmse (test)  2.62\n",
      "           latent factor   5, reg  20.0, rmse (train)  2.57, rmse (test)  2.61\n",
      "           latent factor   5, reg 100.0, rmse (train)  2.57, rmse (test)  2.61\n",
      "           latent factor  15, reg   0.0, rmse (train)  2.36, rmse (test)  2.51\n",
      "           latent factor  15, reg   0.1, rmse (train)  2.36, rmse (test)  2.52\n",
      "           latent factor  15, reg   5.0, rmse (train)  2.35, rmse (test)  2.51\n",
      "           latent factor  15, reg  20.0, rmse (train)  2.35, rmse (test)  2.51\n",
      "           latent factor  15, reg 100.0, rmse (train)  2.36, rmse (test)  2.52\n",
      "LINEAR_RATINGS\n",
      "           latent factor   1, reg   0.0, rmse (train)  1.25, rmse (test)  1.34\n",
      "           latent factor   1, reg   0.1, rmse (train)  1.33, rmse (test)  1.51\n",
      "           latent factor   1, reg   5.0, rmse (train)  1.25, rmse (test)  1.36\n",
      "           latent factor   1, reg  20.0, rmse (train)  1.23, rmse (test)  1.38\n",
      "           latent factor   1, reg 100.0, rmse (train)  1.33, rmse (test)  1.56\n",
      "           latent factor   2, reg   0.0, rmse (train)  0.91, rmse (test)  1.07\n",
      "           latent factor   2, reg   0.1, rmse (train)  0.89, rmse (test)  0.99\n",
      "           latent factor   2, reg   5.0, rmse (train)  0.91, rmse (test)  1.04\n",
      "           latent factor   2, reg  20.0, rmse (train)  0.92, rmse (test)  1.07\n",
      "           latent factor   2, reg 100.0, rmse (train)  0.91, rmse (test)  1.03\n",
      "           latent factor   5, reg   0.0, rmse (train)  0.82, rmse (test)  1.07\n",
      "           latent factor   5, reg   0.1, rmse (train)  0.82, rmse (test)  1.08\n",
      "           latent factor   5, reg   5.0, rmse (train)  0.81, rmse (test)  1.04\n",
      "           latent factor   5, reg  20.0, rmse (train)  0.81, rmse (test)  1.07\n",
      "           latent factor   5, reg 100.0, rmse (train)  0.81, rmse (test)  1.07\n",
      "           latent factor  15, reg   0.0, rmse (train)  0.64, rmse (test)  1.31\n",
      "           latent factor  15, reg   0.1, rmse (train)  0.64, rmse (test)  1.29\n",
      "           latent factor  15, reg   5.0, rmse (train)  0.64, rmse (test)  1.32\n",
      "           latent factor  15, reg  20.0, rmse (train)  0.63, rmse (test)  1.34\n",
      "           latent factor  15, reg 100.0, rmse (train)  0.63, rmse (test)  1.28\n",
      "LOG_RATINGS\n",
      "           latent factor   1, reg   0.0, rmse (train)  0.93, rmse (test)  0.96\n",
      "           latent factor   1, reg   0.1, rmse (train)  0.93, rmse (test)  0.96\n",
      "           latent factor   1, reg   5.0, rmse (train)  0.93, rmse (test)  0.96\n",
      "           latent factor   1, reg  20.0, rmse (train)  0.93, rmse (test)  0.96\n",
      "           latent factor   1, reg 100.0, rmse (train)  0.93, rmse (test)  0.96\n",
      "           latent factor   2, reg   0.0, rmse (train)  0.88, rmse (test)  0.95\n",
      "           latent factor   2, reg   0.1, rmse (train)  0.87, rmse (test)  0.95\n",
      "           latent factor   2, reg   5.0, rmse (train)  0.87, rmse (test)  0.95\n",
      "           latent factor   2, reg  20.0, rmse (train)  0.88, rmse (test)  0.95\n",
      "           latent factor   2, reg 100.0, rmse (train)  0.87, rmse (test)  0.95\n",
      "           latent factor   5, reg   0.0, rmse (train)  0.80, rmse (test)  0.99\n",
      "           latent factor   5, reg   0.1, rmse (train)  0.80, rmse (test)  0.99\n",
      "           latent factor   5, reg   5.0, rmse (train)  0.80, rmse (test)  0.99\n",
      "           latent factor   5, reg  20.0, rmse (train)  0.80, rmse (test)  0.98\n",
      "           latent factor   5, reg 100.0, rmse (train)  0.80, rmse (test)  0.99\n",
      "           latent factor  15, reg   0.0, rmse (train)  0.60, rmse (test)  1.19\n",
      "           latent factor  15, reg   0.1, rmse (train)  0.60, rmse (test)  1.21\n",
      "           latent factor  15, reg   5.0, rmse (train)  0.60, rmse (test)  1.20\n",
      "           latent factor  15, reg  20.0, rmse (train)  0.60, rmse (test)  1.19\n",
      "           latent factor  15, reg 100.0, rmse (train)  0.60, rmse (test)  1.22\n"
     ]
    }
   ],
   "source": [
    "for wt_type in wt_types:\n",
    "    print(wt_type)\n",
    "    for lf in latent_factors:\n",
    "        for r in regularizations:\n",
    "            PARAMS[\"wt_type\"] = wt_type\n",
    "            PARAMS[\"latent_factors\"] = lf\n",
    "            PARAMS[\"regularizations\"] = r\n",
    "\n",
    "            graph,model,input_tensor = define_graph(tr_sparse,PARAMS)\n",
    "            sess = train(graph,model,input_tensor)\n",
    "\n",
    "            output_row = model.row_factors[0].eval(session=sess)\n",
    "            output_col = model.col_factors[0].eval(session=sess)        \n",
    "\n",
    "            rmse_train, _ = get_rmse(output_row, output_col, tr_sparse)\n",
    "            rmse_test, rate_preds_test = get_rmse(output_row, output_col, test_sparse)\n",
    "            print(\"{:10} latent factor {:3.0f}, reg {:5.1f}, rmse (train) {:5.2f}, rmse (test) {:5.2f}\".format(\" \",\n",
    "                                                                                                               lf,\n",
    "                                                                                                               r,\n",
    "                                                                                                               rmse_train,\n",
    "                                                                                                               rmse_test))\n",
    "            if rmse_test < rmse_best:\n",
    "                rmse_best = rmse_test\n",
    "                out = {\n",
    "#                       \"rate_preds_test\":rate_preds_test,\n",
    "                      \"rmse\":rmse_test,\n",
    "                      \"output_row\":output_row,\n",
    "                      \"output_col\":output_col,\n",
    "                      \"params\": PARAMS\n",
    "                      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the parameters that gave the best Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 0.9464870272485855,\n",
       " 'output_row': array([[0.18383189, 0.7959356 ],\n",
       "        [0.32868737, 0.6887443 ],\n",
       "        [0.5603745 , 0.3657162 ],\n",
       "        ...,\n",
       "        [0.44000283, 0.65004677],\n",
       "        [0.64669406, 0.60879785],\n",
       "        [0.49036273, 0.6062054 ]], dtype=float32),\n",
       " 'output_col': array([[ 2.8985252 ,  4.26063   ],\n",
       "        [ 2.8035667 ,  3.145607  ],\n",
       "        [ 2.2716706 ,  3.2159824 ],\n",
       "        ...,\n",
       "        [ 1.8420905 , -0.18509825],\n",
       "        [-0.35046592,  2.7877023 ],\n",
       "        [-1.6071336 ,  3.0399823 ]], dtype=float32),\n",
       " 'params': {'regularization': 0.01,\n",
       "  'unobs_weight': 0.001,\n",
       "  'feature_wt_factor': 189.8,\n",
       "  'feature_wt_exp': 0.08,\n",
       "  'wt_type': 'LOG_RATINGS',\n",
       "  'latent_factors': 15,\n",
       "  'regularizations': 100}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters gave the best Root mean squared error:<br>\n",
    "Parameters:\n",
    "- Regularization = 0.01\n",
    "- unobs_weight : 0.001,\n",
    "- feature_wt_factor : 189.8,\n",
    "- feature_wt_exp: 0.08,\n",
    "- wt_type : LOG_RATINGS,\n",
    "- latent_factors : 15,\n",
    "-  regularizations: 100"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
